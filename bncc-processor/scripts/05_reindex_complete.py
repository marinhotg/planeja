#!/usr/bin/env python3
"""
Script: Re-indexaÃ§Ã£o completa no Pinecone com EF+EM
Execute: python scripts/05_reindex_complete.py
"""

import json
import os
from dotenv import load_dotenv
from pinecone import Pinecone, ServerlessSpec
from typing import List, Dict
import time

load_dotenv()

class PineconeCompleteReindexer:
    def __init__(self):
        self.api_key = os.getenv("PINECONE_API_KEY")
        self.index_name = os.getenv("PINECONE_INDEX_NAME", "bncc-planeja")
        self.dimension = 384
        
        if not self.api_key:
            raise ValueError("PINECONE_API_KEY nÃ£o encontrada")
        
        print(f"ğŸ”‘ Conectando ao Pinecone...")
        self.pc = Pinecone(api_key=self.api_key)
        print("âœ… Conectado ao Pinecone!")
        
    def recreate_index(self):
        """Recria Ã­ndice para base completa"""
        
        # Deletar Ã­ndice existente
        existing_indexes = [index.name for index in self.pc.list_indexes()]
        
        if self.index_name in existing_indexes:
            print(f"ğŸ—‘ï¸  Deletando Ã­ndice existente '{self.index_name}'...")
            self.pc.delete_index(self.index_name)
            
            while self.index_name in [index.name for index in self.pc.list_indexes()]:
                print("   â³ Aguardando deleÃ§Ã£o...")
                time.sleep(2)
            
            print("âœ… Ãndice deletado!")
        
        # Criar novo Ã­ndice
        print(f"ğŸ”„ Criando novo Ã­ndice '{self.index_name}'...")
        
        self.pc.create_index(
            name=self.index_name,
            dimension=self.dimension,
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            )
        )
        
        # Aguardar Ã­ndice ficar ativo
        print("â³ Aguardando Ã­ndice ficar ativo...")
        while True:
            index_description = self.pc.describe_index(self.index_name)
            if index_description.status.ready:
                break
            time.sleep(5)
        
        print("âœ… Novo Ã­ndice criado e ativo!")
        return self.pc.Index(self.index_name)
    
    def prepare_vectors_complete(self, chunks_with_embeddings: List[Dict]) -> List[Dict]:
        """Prepara vetores da base completa"""
        
        print("ğŸ”„ Preparando vetores completos...")
        
        vectors = []
        ef_count = 0
        em_count = 0
        outros_count = 0
        
        for chunk in chunks_with_embeddings:
            # Verificar ID ASCII
            try:
                chunk["id"].encode('ascii')
            except UnicodeEncodeError:
                print(f"âš ï¸  ID nÃ£o-ASCII encontrado: {chunk['id']}")
                continue
            
            # Preparar metadata otimizada
            metadata = {
                "type": chunk["type"],
                "content": chunk["content"][:700],  # Reduzir para caber mais dados
                "area": chunk["metadata"].get("area", "")[:50],
                "etapa": chunk["metadata"].get("etapa", "")[:30],
                "adaptavel_eja": chunk["metadata"].get("adaptavel_eja", True),
                "fonte": chunk["metadata"].get("fonte", "bncc")[:30]
            }
            
            # Campos especÃ­ficos por tipo
            if chunk["type"] == "competencia_geral":
                metadata["comp_num"] = chunk["metadata"].get("competencia_numero", 0)
            elif "habilidades" in chunk["type"]:
                metadata["ano"] = chunk["metadata"].get("ano", "")[:20]
                codigos = chunk["metadata"].get("codigos_habilidades", [])
                metadata["codigos"] = ",".join(codigos[:3])[:60]  # MÃ¡ximo 3 cÃ³digos
                
                # Contar por etapa
                if chunk["metadata"].get("etapa") == "ensino_fundamental":
                    ef_count += 1
                elif chunk["metadata"].get("etapa") == "ensino_medio":
                    em_count += 1
                else:
                    outros_count += 1
            
            vector = {
                "id": chunk["id"],
                "values": chunk["embedding"],
                "metadata": metadata
            }
            
            vectors.append(vector)
        
        print(f"ğŸ“Š Vetores preparados por etapa:")
        print(f"  - Ensino Fundamental: {ef_count}")
        print(f"  - Ensino MÃ©dio: {em_count}")
        print(f"  - Outros/Gerais: {outros_count}")
        print(f"  - Total: {len(vectors)}")
        
        return vectors
    
    def index_vectors_complete(self, chunks_with_embeddings: List[Dict]):
        """Indexa vetores completos no Pinecone"""
        
        # Recriar Ã­ndice
        index = self.recreate_index()
        
        # Preparar vetores
        vectors = self.prepare_vectors_complete(chunks_with_embeddings)
        
        if not vectors:
            print("âŒ Nenhum vetor vÃ¡lido!")
            return None
        
        # Indexar em batches
        batch_size = 50
        total_batches = (len(vectors) + batch_size - 1) // batch_size
        successful_batches = 0
        
        for i in range(0, len(vectors), batch_size):
            batch = vectors[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"ğŸ”„ Indexando batch {batch_num}/{total_batches} ({len(batch)} vetores)")
            
            try:
                index.upsert(vectors=batch)
                print(f"  âœ… Batch {batch_num} indexado com sucesso")
                successful_batches += 1
                time.sleep(1)  # Pausa entre batches
                
            except Exception as e:
                print(f"  âŒ Erro no batch {batch_num}: {e}")
                continue
        
        # Aguardar indexaÃ§Ã£o
        print("â³ Aguardando indexaÃ§Ã£o completar...")
        time.sleep(15)
        
        # Verificar estatÃ­sticas
        stats = index.describe_index_stats()
        print(f"ğŸ“Š EstatÃ­sticas finais:")
        print(f"  - Total de vetores: {stats['total_vector_count']}")
        print(f"  - DimensÃµes: {stats['dimension']}")
        print(f"  - Batches bem-sucedidos: {successful_batches}/{total_batches}")
        
        return index
    
    def test_search_complete(self, index):
        """Teste completo de busca EF+EM"""
        
        print(f"\nğŸ” Testando busca completa...")
        
        queries = [
            "matemÃ¡tica ensino fundamental EJA",
            "portuguÃªs jovens adultos",
            "ensino mÃ©dio linguagens tecnologias", 
            "ciÃªncias natureza EM",
            "projeto vida trabalho",
            "competÃªncias gerais BNCC"
        ]
        
        try:
            from sentence_transformers import SentenceTransformer
            model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
            
            all_tests_passed = True
            
            for query in queries:
                print(f"\nğŸ” Query: '{query}'")
                
                query_embedding = model.encode([query], normalize_embeddings=True)[0].tolist()
                
                results = index.query(
                    vector=query_embedding,
                    top_k=3,
                    include_metadata=True
                )
                
                if results.matches:
                    print(f"  ğŸ“Š {len(results.matches)} resultados:")
                    for i, match in enumerate(results.matches):
                        area = match.metadata.get('area', 'N/A')
                        etapa = match.metadata.get('etapa', 'N/A')
                        tipo = match.metadata.get('type', 'N/A')
                        print(f"    {i+1}. Score: {match.score:.3f} | {tipo} | {area} | {etapa}")
                else:
                    print(f"  âŒ Nenhum resultado")
                    all_tests_passed = False
            
            return all_tests_passed
            
        except Exception as e:
            print(f"âŒ Erro no teste: {e}")
            return False

def main():
    print("ğŸš€ RE-INDEXAÃ‡ÃƒO COMPLETA PINECONE (EF+EM)\n")
    
    # Carregar chunks com embeddings
    input_file = "data/processed/bncc_chunks_complete_embeddings.json"
    
    if not os.path.exists(input_file):
        print(f"âŒ Arquivo nÃ£o encontrado: {input_file}")
        print("   Execute primeiro: python scripts/04_generate_embeddings_complete.py")
        return
    
    print(f"ğŸ“¥ Carregando chunks completos...")
    with open(input_file, "r", encoding="utf-8") as f:
        chunks_with_embeddings = json.load(f)
    
    print(f"ğŸ“Š Carregados {len(chunks_with_embeddings)} chunks")
    
    # Re-indexar
    try:
        indexer = PineconeCompleteReindexer()
        index = indexer.index_vectors_complete(chunks_with_embeddings)
        
        if index:
            # Teste de busca
            if indexer.test_search_complete(index):
                print(f"\nğŸ‰ RE-INDEXAÃ‡ÃƒO COMPLETA FINALIZADA!")
                print(f"ğŸ”— Ãndice: {indexer.index_name}")
                print(f"ğŸ“Š Base BNCC completa (EF+EM) indexada!")
                print(f"ğŸ¯ Pronta para gerar planos de aula completos!")
            else:
                print(f"\nâš ï¸  IndexaÃ§Ã£o concluÃ­da mas alguns testes falharam")
        
    except Exception as e:
        print(f"âŒ Erro: {e}")

if __name__ == "__main__":
    main()