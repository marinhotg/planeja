#!/usr/bin/env python3
"""
Script: ValidaÃ§Ã£o final da base completa EF+EM
Execute: python scripts/06_validate_complete.py
"""

import json
import os
from dotenv import load_dotenv
from pinecone import Pinecone
from sentence_transformers import SentenceTransformer

load_dotenv()

def validate_complete_files():
    """Valida arquivos da base completa"""
    
    print("ğŸ“ Validando arquivos completos...")
    
    required_files = [
        "data/bncc_raw/bncc_ei_ef.pdf",
        "data/processed/bncc_extracted_complete.json",
        "data/processed/bncc_chunks_complete.json", 
        "data/processed/bncc_chunks_complete_embeddings.json"
    ]
    
    all_good = True
    
    for file_path in required_files:
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024 * 1024)
            print(f"  âœ… {file_path} ({size_mb:.1f} MB)")
        else:
            print(f"  âŒ {file_path} - ARQUIVO FALTANDO")
            all_good = False
    
    return all_good

def validate_complete_data_quality():
    """Valida qualidade dos dados completos"""
    
    print(f"\nğŸ“Š Validando qualidade dos dados completos...")
    
    # Dados extraÃ­dos
    with open("data/processed/bncc_extracted_complete.json", "r", encoding="utf-8") as f:
        extracted = json.load(f)
    
    # Chunks
    with open("data/processed/bncc_chunks_complete.json", "r", encoding="utf-8") as f:
        chunks = json.load(f)
    
    # Chunks com embeddings
    with open("data/processed/bncc_chunks_complete_embeddings.json", "r", encoding="utf-8") as f:
        chunks_embeddings = json.load(f)
    
    print(f"  ğŸ“ˆ CompetÃªncias gerais: {len(extracted['competencias_gerais'])}")
    print(f"  ğŸ“ˆ Total de habilidades: {len(extracted['habilidades'])}")
    print(f"    - Ensino Fundamental: {extracted['metadata']['ensino_fundamental']}")
    print(f"    - Ensino MÃ©dio: {extracted['metadata']['ensino_medio']}")
    print(f"  ğŸ“ˆ Chunks criados: {len(chunks)}")
    print(f"  ğŸ“ˆ Chunks com embeddings: {len(chunks_embeddings)}")
    
    # Validar distribuiÃ§Ã£o das Ã¡reas
    areas = {}
    for hab in extracted['habilidades']:
        area = hab['area']
        areas[area] = areas.get(area, 0) + 1
    
    print(f"  ğŸ“š Ãreas de conhecimento:")
    for area in sorted(areas.keys()):
        count = areas[area]
        print(f"    - {area}: {count} habilidades")
    
    # Validar chunks por tipo
    chunk_types = {}
    for chunk in chunks:
        chunk_type = chunk['type']
        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
    
    print(f"  ğŸ“¦ DistribuiÃ§Ã£o de chunks:")
    for chunk_type in sorted(chunk_types.keys()):
        count = chunk_types[chunk_type]
        print(f"    - {chunk_type}: {count}")
    
    # Validar embeddings
    if chunks_embeddings:
        embedding_dim = chunks_embeddings[0]['embedding_dimensions']
        print(f"  ğŸ§  DimensÃµes dos embeddings: {embedding_dim}")
    
    # Verificar cÃ³digos especÃ­ficos mencionados
    target_codes = ["EM13LGG101", "EM13LGG102", "EM13LGG103", "EM13LGG104", "EM13LGG105"]
    found_codes = [h for h in extracted['habilidades'] if h['codigo'] in target_codes]
    
    print(f"  ğŸ¯ CÃ³digos especÃ­ficos encontrados: {len(found_codes)}/5")
    for hab in found_codes:
        print(f"    âœ… {hab['codigo']}: {hab['descricao'][:60]}...")

def validate_complete_pinecone():
    """Valida Pinecone com base completa"""
    
    print(f"\nğŸ”— Validando Pinecone completo...")
    
    api_key = os.getenv("PINECONE_API_KEY")
    index_name = os.getenv("PINECONE_INDEX_NAME", "bncc-planeja")
    
    if not api_key:
        print("  âŒ PINECONE_API_KEY nÃ£o encontrada")
        return False
    
    try:
        pc = Pinecone(api_key=api_key)
        
        # Verificar Ã­ndice
        existing_indexes = [index.name for index in pc.list_indexes()]
        
        if index_name not in existing_indexes:
            print(f"  âŒ Ãndice '{index_name}' nÃ£o encontrado")
            return False
        
        print(f"  âœ… Ãndice '{index_name}' encontrado")
        
        # EstatÃ­sticas do Ã­ndice
        index = pc.Index(index_name)
        stats = index.describe_index_stats()
        
        print(f"  ğŸ“Š Vetores indexados: {stats['total_vector_count']}")
        print(f"  ğŸ“Š DimensÃµes: {stats['dimension']}")
        
        if stats['total_vector_count'] == 0:
            print("  âš ï¸  Nenhum vetor no Ã­ndice")
            return False
        
        return True
        
    except Exception as e:
        print(f"  âŒ Erro: {e}")
        return False

def test_complete_end_to_end():
    """Teste end-to-end completo EF+EM"""
    
    print(f"\nğŸ§ª Teste End-to-End Completo...")
    
    try:
        # Carregar modelo
        model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        
        # Conectar Pinecone
        pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
        index = pc.Index(os.getenv("PINECONE_INDEX_NAME", "bncc-planeja"))
        
        # Queries de teste especÃ­ficas EF+EM
        test_queries = [
            ("Ensino Fundamental", "matemÃ¡tica bÃ¡sica para adultos"),
            ("Ensino MÃ©dio", "linguagens tecnologias jovens"),
            ("EJA Geral", "competÃªncias BNCC educaÃ§Ã£o adultos"),
            ("Mundo Trabalho", "projeto vida ensino mÃ©dio"),
            ("ContextualizaÃ§Ã£o", "conteÃºdos significativos EJA")
        ]
        
        all_tests_passed = True
        
        for categoria, query in test_queries:
            print(f"\n  ğŸ” {categoria}: '{query}'")
            
            query_embedding = model.encode([query], normalize_embeddings=True)[0].tolist()
            
            results = index.query(
                vector=query_embedding,
                top_k=2,
                include_metadata=True
            )
            
            if results.matches:
                for i, match in enumerate(results.matches):
                    tipo = match.metadata.get('type', 'N/A')
                    area = match.metadata.get('area', 'N/A')
                    etapa = match.metadata.get('etapa', 'N/A')
                    print(f"    {i+1}. Score: {match.score:.3f} | {tipo} | {etapa} | {area}")
            else:
                print(f"    âŒ Nenhum resultado")
                all_tests_passed = False
        
        print(f"\n  âœ… Teste end-to-end completo concluÃ­do!")
        return all_tests_passed
        
    except Exception as e:
        print(f"  âŒ Erro no teste: {e}")
        return False

def generate_final_report():
    """Gera relatÃ³rio final da base completa"""
    
    print(f"\nğŸ“‹ RELATÃ“RIO FINAL DA BASE BNCC COMPLETA")
    print(f"=" * 50)
    
    # Carregar dados para relatÃ³rio
    with open("data/processed/bncc_extracted_complete.json", "r", encoding="utf-8") as f:
        extracted = json.load(f)
    
    with open("data/processed/bncc_chunks_complete_embeddings.json", "r", encoding="utf-8") as f:
        chunks = json.load(f)
    
    # EstatÃ­sticas gerais
    print(f"ğŸ“Š ESTATÃSTICAS GERAIS:")
    print(f"  - Total de habilidades extraÃ­das: {len(extracted['habilidades'])}")
    print(f"  - Ensino Fundamental (EF): {extracted['metadata']['ensino_fundamental']}")
    print(f"  - Ensino MÃ©dio (EM): {extracted['metadata']['ensino_medio']}")
    print(f"  - CompetÃªncias gerais: {len(extracted['competencias_gerais'])}")
    print(f"  - Chunks indexados: {len(chunks)}")
    
    # Ãreas EM especÃ­ficas
    em_areas = {}
    for hab in extracted['habilidades']:
        if hab['codigo'].startswith('EM'):
            area = hab['area']
            em_areas[area] = em_areas.get(area, 0) + 1
    
    print(f"\nğŸ“ ENSINO MÃ‰DIO POR ÃREA:")
    for area, count in sorted(em_areas.items()):
        print(f"  - {area}: {count} habilidades")
    
    # Capacidades da base
    print(f"\nğŸ¯ CAPACIDADES DA BASE:")
    print(f"  âœ… GeraÃ§Ã£o de planos para Ensino Fundamental")
    print(f"  âœ… GeraÃ§Ã£o de planos para Ensino MÃ©dio")
    print(f"  âœ… ContextualizaÃ§Ã£o especÃ­fica para EJA")
    print(f"  âœ… Busca semÃ¢ntica por Ã¡rea/competÃªncia")
    print(f"  âœ… AdaptaÃ§Ã£o para diferentes perfis de alunos")
    print(f"  âœ… Alinhamento completo com BNCC")

def main():
    print("ğŸ” VALIDAÃ‡ÃƒO COMPLETA DA BASE BNCC (EF+EM)\n")
    
    # ValidaÃ§Ãµes
    files_ok = validate_complete_files()
    validate_complete_data_quality()
    pinecone_ok = validate_complete_pinecone()
    e2e_ok = test_complete_end_to_end()
    
    # RelatÃ³rio final
    generate_final_report()
    
    # Resultado
    print(f"\n{'='*60}")
    print("ğŸ“‹ RESULTADO DA VALIDAÃ‡ÃƒO COMPLETA:")
    print(f"  Arquivos: {'âœ…' if files_ok else 'âŒ'}")
    print(f"  Pinecone: {'âœ…' if pinecone_ok else 'âŒ'}")
    print(f"  End-to-End: {'âœ…' if e2e_ok else 'âŒ'}")
    
    if files_ok and pinecone_ok and e2e_ok:
        print(f"\nğŸ‰ BASE BNCC COMPLETA (EF+EM) FUNCIONAL!")
        print(f"ğŸš€ Pronta para gerar planos de aula completos!")
        print(f"ğŸ¯ Inclui Ensino Fundamental + Ensino MÃ©dio + EJA!")
    else:
        print(f"\nâš ï¸  Alguns problemas encontrados. Verifique os logs.")

if __name__ == "__main__":
    main()